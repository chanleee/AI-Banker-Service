{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caef9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import numpy as np\n",
    "import wavio\n",
    "import sounddevice as sd\n",
    "from playsound import playsound\n",
    "from openai import OpenAI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from typing import List\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from financial_assistant_define import cosine_similarity, get_relevant_context, get_transcript, get_ai_response, play_ai_response_with_tts, process_voice_query\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "DB_VECTORS_FILE = \"financial_db.npy\"\n",
    "DB_CHUNKS_FILE = \"financial_db_chunks.pkl\"\n",
    "SPEECH_FILE_PATH = \"./response.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b049db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel:\n",
    "    def __init__(self, model_name=\"text-embedding-3-small\"):\n",
    "        self.client = client\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def get_embedding(self, text: str) -> List[float]:\n",
    "        response = self.client.embeddings.create(input=text, model=self.model_name)\n",
    "        return response.data[0].embedding\n",
    "\n",
    "EMBEDDING_MODEL = EmbeddingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02647e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(audio_file_path: str):\n",
    "    if not os.path.exists(audio_file_path):\n",
    "        print(f\"error: cannot find'{audio_file_path}'\")\n",
    "        print(\"upload the speech file and check the file name.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"start processing '{audio_file_path}'\")\n",
    "    user_transcript = get_transcript(audio_file_path)\n",
    "    if user_transcript:\n",
    "        ai_response = get_ai_response(user_transcript)\n",
    "        play_ai_response_with_tts(ai_response)\n",
    "    print(\"\\nfinish task.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_AUDIO_FILE = \"my_question.m4a\" \n",
    "    main(INPUT_AUDIO_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
